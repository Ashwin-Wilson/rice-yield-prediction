{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfa4750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bbb5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Harvested Area</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aceh</td>\n",
       "      <td>329516</td>\n",
       "      <td>2336</td>\n",
       "      <td>81</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aceh</td>\n",
       "      <td>310012</td>\n",
       "      <td>1437</td>\n",
       "      <td>82</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aceh</td>\n",
       "      <td>317869</td>\n",
       "      <td>1790</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aceh</td>\n",
       "      <td>297058</td>\n",
       "      <td>2293</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aceh</td>\n",
       "      <td>271750</td>\n",
       "      <td>1834</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Papua</td>\n",
       "      <td>54132</td>\n",
       "      <td>1823</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Papua</td>\n",
       "      <td>52728</td>\n",
       "      <td>1502</td>\n",
       "      <td>75</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Papua</td>\n",
       "      <td>64985</td>\n",
       "      <td>2028</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Papua</td>\n",
       "      <td>49742</td>\n",
       "      <td>2576</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Papua</td>\n",
       "      <td>49323</td>\n",
       "      <td>2555</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province  Harvested Area  Rainfall  Humidity  Temperature\n",
       "0       Aceh          329516      2336        81           28\n",
       "1       Aceh          310012      1437        82           27\n",
       "2       Aceh          317869      1790        76           29\n",
       "3       Aceh          297058      2293        76           29\n",
       "4       Aceh          271750      1834        76           29\n",
       "..       ...             ...       ...       ...          ...\n",
       "199    Papua           54132      1823        77           28\n",
       "200    Papua           52728      1502        75           28\n",
       "201    Papua           64985      2028        76           28\n",
       "202    Papua           49742      2576        84           28\n",
       "203    Papua           49323      2555        80           28\n",
       "\n",
       "[204 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading, Preparing and Scaling\n",
    "df = pd.read_csv(\"./dataset.csv\")\n",
    "input_n = df.drop(['Production','Year'], axis='columns')\n",
    "input_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cd0ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1861567\n",
       "1      1714438\n",
       "2      1757313\n",
       "3      1634640\n",
       "4      1509456\n",
       "        ...   \n",
       "199     235340\n",
       "200     166002\n",
       "201     286280\n",
       "202     193944\n",
       "203     200115\n",
       "Name: Production, Length: 204, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['Production']\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8de7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Harvested Area</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>329516</td>\n",
       "      <td>2336</td>\n",
       "      <td>81</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>310012</td>\n",
       "      <td>1437</td>\n",
       "      <td>82</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>317869</td>\n",
       "      <td>1790</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>297058</td>\n",
       "      <td>2293</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>271750</td>\n",
       "      <td>1834</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>23</td>\n",
       "      <td>54132</td>\n",
       "      <td>1823</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>23</td>\n",
       "      <td>52728</td>\n",
       "      <td>1502</td>\n",
       "      <td>75</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>23</td>\n",
       "      <td>64985</td>\n",
       "      <td>2028</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>23</td>\n",
       "      <td>49742</td>\n",
       "      <td>2576</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>23</td>\n",
       "      <td>49323</td>\n",
       "      <td>2555</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province  Harvested Area  Rainfall  Humidity  Temperature\n",
       "0           0          329516      2336        81           28\n",
       "1           0          310012      1437        82           27\n",
       "2           0          317869      1790        76           29\n",
       "3           0          297058      2293        76           29\n",
       "4           0          271750      1834        76           29\n",
       "..        ...             ...       ...       ...          ...\n",
       "199        23           54132      1823        77           28\n",
       "200        23           52728      1502        75           28\n",
       "201        23           64985      2028        76           28\n",
       "202        23           49742      2576        84           28\n",
       "203        23           49323      2555        80           28\n",
       "\n",
       "[204 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_province = LabelEncoder()\n",
    "input_n['Province'] = le_province.fit_transform(input_n['Province'])\n",
    "input_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fb5b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Province  Harvested Area  Rainfall  Humidity  Temperature\n",
      "199  0.696970        0.029636  0.276728  0.363636          0.6\n",
      "93   0.060606        0.174608  0.516504  0.272727          0.8\n",
      "38   0.090909        0.035128  0.785344  0.363636          0.8\n",
      "24   0.212121        0.047240  0.446959  0.727273          0.4\n",
      "96   0.030303        0.060839  0.222960  0.500000          0.6\n",
      "..        ...             ...       ...       ...          ...\n",
      "106  0.636364        0.148176  0.448412  0.409091          0.8\n",
      "14   0.939394        0.162212  0.880424  1.000000          0.6\n",
      "92   0.060606        0.178497  0.458377  0.227273          1.0\n",
      "179  0.787879        0.032372  0.428690  0.500000          0.6\n",
      "102  0.636364        0.158688  0.244551  0.227273          0.8\n",
      "\n",
      "[163 rows x 5 columns]\n",
      "[2.23748270e-02 1.52662045e-01 2.78508815e-02 3.64431838e-02\n",
      " 6.34951446e-02 6.96679212e-02 2.61100764e-02 2.19494598e-02\n",
      " 4.26319617e-04 2.85469368e-02 2.31739381e-02 1.60713733e-01\n",
      " 1.32682075e-01 4.94595523e-02 4.25186193e-03 2.81174741e-03\n",
      " 2.27865740e-03 2.29189655e-03 4.70768199e-01 9.19618941e-01\n",
      " 3.36302935e-02 5.06464085e-02 2.47921906e-01 1.41216278e-01\n",
      " 2.63033965e-01 4.22069755e-02 2.36992085e-01 9.16095137e-01\n",
      " 2.22731998e-03 6.55280682e-02 6.67414980e-03 2.41347764e-02\n",
      " 5.04426781e-02 2.63722877e-02 8.07161331e-02 7.61291017e-02\n",
      " 3.67638760e-02 7.80058224e-02 6.36421087e-02 7.19701995e-02\n",
      " 1.67336164e-01 8.63048823e-01 2.55995310e-01 2.49877966e-02\n",
      " 8.82504466e-02 9.12502185e-01 2.27639055e-02 2.74677081e-02\n",
      " 7.72729069e-02 2.79641286e-04 2.03000905e-02 4.84820841e-01\n",
      " 2.52439123e-03 2.43068854e-01 1.98133852e-01 2.12108296e-02\n",
      " 2.21409988e-02 2.00764727e-01 2.83571122e-02 2.28161001e-03\n",
      " 1.43728858e-01 2.61224297e-01 1.25416355e-01 2.56322288e-02\n",
      " 2.22846293e-02 5.12853165e-02 1.98888293e-01 3.92507404e-04\n",
      " 7.21087820e-02 4.63122544e-03 2.28315299e-02 1.77265906e-01\n",
      " 1.10847863e-02 2.36643581e-02 8.98480974e-01 1.09521471e-01\n",
      " 1.82395457e-04 2.52388357e-01 2.04652465e-02 2.64136243e-02\n",
      " 2.67818441e-02 8.56747179e-02 4.35776559e-02 4.48420612e-01\n",
      " 3.13682088e-03 5.07040322e-02 2.94794872e-02 1.98841527e-02\n",
      " 2.19815576e-02 2.64166722e-02 5.29668788e-02 2.57824313e-02\n",
      " 4.55783865e-02 2.59864284e-01 1.70314496e-01 1.04793095e-02\n",
      " 2.06079817e-01 7.95167044e-02 1.55652092e-01 1.35166654e-01\n",
      " 6.19839768e-03 2.81393806e-03 8.77955533e-03 2.31227912e-02\n",
      " 2.63144736e-03 4.60827123e-03 4.98109135e-02 2.64273016e-01\n",
      " 1.97966124e-01 6.90151074e-02 1.40018754e-01 5.07070800e-02\n",
      " 1.10300200e-02 7.87129262e-03 9.13501121e-01 1.94308500e-01\n",
      " 1.41208658e-01 0.00000000e+00 7.73894876e-02 9.67592185e-02\n",
      " 1.38780465e-01 1.00000000e+00 1.84320372e-02 6.96058210e-02\n",
      " 5.10492596e-01 3.57390326e-03 2.69164262e-04 6.41955813e-05\n",
      " 1.47287618e-01 5.41957384e-03 1.57706827e-02 7.08614447e-02\n",
      " 8.00063624e-06 4.31481932e-03 9.07319106e-01 2.06717391e-02\n",
      " 4.11461292e-05 2.16401971e-02 2.24217831e-03 6.77649127e-02\n",
      " 2.81973852e-02 7.54179975e-02 2.33770971e-03 1.63252506e-01\n",
      " 5.81017633e-03 3.01028701e-02 3.62664079e-02 8.04331583e-02\n",
      " 1.33511474e-01 5.89083037e-02 1.26397575e-01 9.32375575e-01\n",
      " 9.03761585e-01 1.27861501e-01 1.90197982e-02 2.31696521e-02\n",
      " 4.09175396e-03 8.66308416e-01 1.38346430e-01 1.32091076e-01\n",
      " 1.57607486e-01 2.79645096e-02 1.39050677e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_n,  # your feature dataframe\n",
    "    target,    # your target array/series\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#scaling feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "#scale features\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=[\"Province\",\"Harvested Area\",\"Rainfall\",\"Humidity\",\"Temperature\"], index=X_train.index)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "print(X_train_scaled)\n",
    "print(y_train_scaled)\n",
    "\n",
    "#Scale test data\n",
    "X_test_scaled = feature_scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=[\"Province\",\"Harvested Area\",\"Rainfall\",\"Humidity\",\"Temperature\"], index=X_test.index)\n",
    "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df5da2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0507 - val_loss: 0.1249\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0562 - val_loss: 0.1079\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0345 - val_loss: 0.1006\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0319 - val_loss: 0.0960\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0348 - val_loss: 0.0919\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0411 - val_loss: 0.0866\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0320 - val_loss: 0.0809\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0326 - val_loss: 0.0737\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: 0.0638\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0248 - val_loss: 0.0530\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.0417\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0180 - val_loss: 0.0322\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0220\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0104 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0116 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0129 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0108 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0110 - val_loss: 0.0039\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0108 - val_loss: 0.0033\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0100 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - val_loss: 0.0020\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0026\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0085 - val_loss: 0.0019\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.0026\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: 0.0036\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0112 - val_loss: 0.0020\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0086 - val_loss: 0.0019\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - val_loss: 0.0025\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0097 - val_loss: 0.0025\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0034\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0095 - val_loss: 0.0027\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0104 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0110 - val_loss: 0.0023\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.0019\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0031\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0091 - val_loss: 0.0027\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.0024\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: 0.0026\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - val_loss: 0.0034\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0105 - val_loss: 0.0032\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0118 - val_loss: 0.0021\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.0031\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0030\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0104 - val_loss: 0.0019\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0019\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0015\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - val_loss: 0.0015\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0076 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0020\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0110 - val_loss: 0.0025\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - val_loss: 0.0021\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0094 - val_loss: 0.0018\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0018\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - val_loss: 0.0024\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0104 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "X_train_reshaped = X_train_scaled.values.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.values.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Update your model's input_shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(1, 5)))  # (timesteps, features)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train with reshaped data\n",
    "history = model.fit(X_train_reshaped, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "599a3c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "RMSE: 1330017.46\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_reshaped)\n",
    "predictions = target_scaler.inverse_transform(predictions).flatten()\n",
    "y_test = target_scaler.inverse_transform(y_test_scaled.reshape(-1,1)).flatten()\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_test - predictions)**2))\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16c6e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "(41,)\n",
      "(41,)\n",
      "Mean Squared Error: 0.016047\n",
      "Mean Absolute Error: 0.070463\n",
      "R² Score: 0.851319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred_scaled = model.predict(X_test_reshaped)\n",
    "print(y_pred_scaled[:,0].shape)\n",
    "print(y_test_scaled.shape)\n",
    "\n",
    "# Regression metrics\n",
    "mse = mean_squared_error(y_test_scaled, y_pred_scaled[:,0])\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred_scaled[:,0])\n",
    "r2 = r2_score(y_test_scaled, y_pred_scaled[:,0])\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dc5f3",
   "metadata": {},
   "source": [
    "# Time Series Approach Using Year Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56107538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (204, 7)\n",
      "Years available: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "Provinces: ['Aceh' 'Sumatera Utara' 'Sumatera Barat' 'Riau' 'Jambi'\n",
      " 'Sumatera Selatan' 'Bengkulu' 'Lampung' 'Kepulauan Bangka Belitung'\n",
      " 'Kepulauan Riau' 'DKI Jakarta' 'Jawa Barat' 'Jawa Tengah' 'DI Yogyakarta'\n",
      " 'Jawa Timur' 'Banten' 'Bali' 'Nusa Tenggara Barat' 'Nusa Tenggara Timur'\n",
      " 'Kalimantan Barat' 'Kalimantan Tengah' 'Kalimantan Selatan'\n",
      " 'Kalimantan Timur' 'Kalimantan Utara' 'Sulawesi Utara' 'Sulawesi Tengah'\n",
      " 'Sulawesi Selatan' 'Sulawesi Tenggara' 'Gorontalo' 'Sulawesi Barat'\n",
      " 'Maluku' 'Maluku Utara' 'Papua Barat' 'Papua']\n",
      "\n",
      "Input features shape: (204, 6)\n",
      "\n",
      "Input features:\n",
      "   Province_encoded  Year  Harvested Area  Rainfall  Humidity  Temperature\n",
      "0                 0  2018          329516      2336        81           28\n",
      "1                 0  2019          310012      1437        82           27\n",
      "2                 0  2020          317869      1790        76           29\n",
      "3                 0  2021          297058      2293        76           29\n",
      "4                 0  2022          271750      1834        76           29\n",
      "5                 0  2023          254319      2555        80           28\n",
      "6                33  2018          408176      2388        79           29\n",
      "7                33  2019          413141      1884        84           27\n",
      "8                33  2020          388591      2741        83           29\n",
      "9                33  2021          385405      2543        77           29\n"
     ]
    }
   ],
   "source": [
    "# 1st cell: Load data and create input features for time series\n",
    "df_ts = pd.read_csv(\"./dataset.csv\")\n",
    "print(\"Dataset shape:\", df_ts.shape)\n",
    "print(\"Years available:\", sorted(df_ts['Year'].unique()))\n",
    "print(\"Provinces:\", df_ts['Province'].unique())\n",
    "\n",
    "# Encode provinces for time series\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_province_ts = LabelEncoder()\n",
    "df_ts['Province_encoded'] = le_province_ts.fit_transform(df_ts['Province'])\n",
    "\n",
    "# Create input features (excluding Production which is our target)\n",
    "input_n_ts = df_ts[['Province_encoded', 'Year', 'Harvested Area', 'Rainfall', 'Humidity', 'Temperature']]\n",
    "print(\"\\nInput features shape:\", input_n_ts.shape)\n",
    "print(\"\\nInput features:\")\n",
    "print(input_n_ts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6d906ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable shape: (204,)\n",
      "\n",
      "Target variable (Production):\n",
      "0    1861567\n",
      "1    1714438\n",
      "2    1757313\n",
      "3    1634640\n",
      "4    1509456\n",
      "5    1393474\n",
      "6    2108285\n",
      "7    2078902\n",
      "8    2040500\n",
      "9    2004143\n",
      "Name: Production, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_ts = df_ts['Production']\n",
    "print(\"Target variable shape:\", target_ts.shape)\n",
    "print(\"\\nTarget variable (Production):\")\n",
    "print(target_ts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b88757bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences shape: [[[     0 329516   2336     81     28]\n",
      "  [     0 310012   1437     82     27]\n",
      "  [     0 317869   1790     76     29]\n",
      "  [     0 297058   2293     76     29]]\n",
      "\n",
      " [[     0 310012   1437     82     27]\n",
      "  [     0 317869   1790     76     29]\n",
      "  [     0 297058   2293     76     29]\n",
      "  [     0 271750   1834     76     29]]\n",
      "\n",
      " [[     0 317869   1790     76     29]\n",
      "  [     0 297058   2293     76     29]\n",
      "  [     0 271750   1834     76     29]\n",
      "  [     0 254319   2555     80     28]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[    23  52412   2991     83     28]\n",
      "  [    23  54132   1823     77     28]\n",
      "  [    23  52728   1502     75     28]\n",
      "  [    23  64985   2028     76     28]]\n",
      "\n",
      " [[    23  54132   1823     77     28]\n",
      "  [    23  52728   1502     75     28]\n",
      "  [    23  64985   2028     76     28]\n",
      "  [    23  49742   2576     84     28]]\n",
      "\n",
      " [[    23  52728   1502     75     28]\n",
      "  [    23  64985   2028     76     28]\n",
      "  [    23  49742   2576     84     28]\n",
      "  [    23  49323   2555     80     28]]]\n",
      "Targets shape: (102,)\n",
      "\n",
      "Training data shape: (81, 4, 5)\n",
      "Training target shape: (81,)\n",
      "Test data shape: (21, 4, 5)\n",
      "Test target shape: (21,)\n"
     ]
    }
   ],
   "source": [
    "# 3rd cell: Structure data for time series, split and scale\n",
    "def create_time_series_sequences(data, target, sequence_length):\n",
    "    \"\"\"\n",
    "    Create time series sequences for LSTM\n",
    "    sequence_length: number of years to look back\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Group by province to create sequences within each province\n",
    "    provinces = data['Province_encoded'].unique()\n",
    "    \n",
    "    for province in provinces:\n",
    "        # Get data for this province, sorted by year\n",
    "        province_data = data[data['Province_encoded'] == province].sort_values('Year')\n",
    "        province_target = target[data['Province_encoded'] == province].reindex(province_data.index)\n",
    "        \n",
    "        # Create sequences for this province\n",
    "        for i in range(len(province_data) - sequence_length + 1):\n",
    "            # Get sequence of features (excluding Year as it's just for ordering)\n",
    "            seq_features = province_data.iloc[i:i+sequence_length][['Province_encoded', 'Harvested Area', 'Rainfall', 'Humidity', 'Temperature']].values\n",
    "            seq_target = province_target.iloc[i+sequence_length-1]  # Predict the last year in sequence\n",
    "            \n",
    "            sequences.append(seq_features)\n",
    "            targets.append(seq_target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Create time series sequences (using 3 years to predict current year)\n",
    "X_sequences, y_sequences = create_time_series_sequences(input_n_ts, target_ts, 4)\n",
    "print(f\"Sequences shape: {X_sequences}\")  # (samples, timesteps, features)\n",
    "print(f\"Targets shape: {y_sequences.shape}\")\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(\n",
    "    X_sequences,\n",
    "    y_sequences,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Scale features and target using MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feature_scaler_ts = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaler_ts = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape for scaling (combine all timesteps and samples for consistent scaling)\n",
    "X_train_reshaped_for_scaling = X_train_ts.reshape(-1, X_train_ts.shape[-1])\n",
    "\n",
    "# print(X_train_reshaped_for_scaling.shape)\n",
    "X_train_scaled_ts = feature_scaler_ts.fit_transform(X_train_reshaped_for_scaling)\n",
    "X_train_scaled_ts = X_train_scaled_ts.reshape(X_train_ts.shape)\n",
    "# Scale target\n",
    "y_train_scaled_ts = target_scaler_ts.fit_transform(y_train_ts.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Scale test data\n",
    "X_test_reshaped_for_scaling = X_test_ts.reshape(-1, X_test_ts.shape[-1])\n",
    "X_test_scaled_ts = feature_scaler_ts.transform(X_test_reshaped_for_scaling)\n",
    "X_test_scaled_ts = X_test_scaled_ts.reshape(X_test_ts.shape)\n",
    "y_test_scaled_ts = target_scaler_ts.transform(y_test_ts.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train_scaled_ts.shape}\")\n",
    "print(f\"Training target shape: {y_train_scaled_ts.shape}\")\n",
    "print(f\"Test data shape: {X_test_scaled_ts.shape}\")\n",
    "print(f\"Test target shape: {y_test_scaled_ts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cee7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled_ts shape: (81, 4, 5)\n",
      "X_test_scaled_ts shape: (21, 4, 5)\n",
      "Model architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_76 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_76 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_77 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_77 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,129</span> (469.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,129\u001b[0m (469.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,129</span> (469.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,129\u001b[0m (469.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.1168 - mae: 0.1661 - val_loss: 0.0053 - val_mae: 0.0704\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0842 - mae: 0.1581 - val_loss: 0.0198 - val_mae: 0.1330\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0652 - mae: 0.1757 - val_loss: 0.0230 - val_mae: 0.1449\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0626 - mae: 0.1796 - val_loss: 0.0137 - val_mae: 0.1099\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0538 - mae: 0.1543 - val_loss: 0.0064 - val_mae: 0.0762\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0403 - mae: 0.1217 - val_loss: 0.0038 - val_mae: 0.0596\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0311 - mae: 0.1021 - val_loss: 0.0054 - val_mae: 0.0684\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0248 - mae: 0.1023 - val_loss: 0.0042 - val_mae: 0.0582\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0661 - val_loss: 0.0017 - val_mae: 0.0318\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0127 - mae: 0.0703 - val_loss: 0.0030 - val_mae: 0.0453\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0089 - mae: 0.0603 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0666 - val_loss: 0.0032 - val_mae: 0.0470\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0125 - mae: 0.0791 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0654 - val_loss: 0.0015 - val_mae: 0.0325\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0584 - val_loss: 0.0028 - val_mae: 0.0483\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0622 - val_loss: 0.0039 - val_mae: 0.0580\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0720 - val_loss: 0.0034 - val_mae: 0.0539\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0584 - val_loss: 0.0020 - val_mae: 0.0388\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0060 - mae: 0.0497 - val_loss: 0.0014 - val_mae: 0.0304\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0086 - mae: 0.0577 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0652 - val_loss: 0.0015 - val_mae: 0.0314\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - mae: 0.0528 - val_loss: 0.0019 - val_mae: 0.0373\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0553 - val_loss: 0.0023 - val_mae: 0.0417\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0101 - mae: 0.0696 - val_loss: 0.0015 - val_mae: 0.0320\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0517 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0520 - val_loss: 0.0012 - val_mae: 0.0284\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0676 - val_loss: 0.0021 - val_mae: 0.0423\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0607 - val_loss: 0.0036 - val_mae: 0.0559\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0580 - val_loss: 0.0028 - val_mae: 0.0489\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0657 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0204\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0619 - val_loss: 0.0010 - val_mae: 0.0201\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0615 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0053 - mae: 0.0493 - val_loss: 0.0018 - val_mae: 0.0402\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0026 - val_mae: 0.0481\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0054 - mae: 0.0592 - val_loss: 0.0025 - val_mae: 0.0476\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0577 - val_loss: 0.0016 - val_mae: 0.0364\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 0.0013 - val_mae: 0.0303\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0605 - val_loss: 0.0013 - val_mae: 0.0320\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0056 - mae: 0.0516 - val_loss: 0.0016 - val_mae: 0.0369\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0048 - mae: 0.0534 - val_loss: 0.0019 - val_mae: 0.0397\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0621 - val_loss: 0.0019 - val_mae: 0.0396\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0537 - val_loss: 0.0016 - val_mae: 0.0364\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0062 - mae: 0.0597 - val_loss: 0.0014 - val_mae: 0.0338\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0505 - val_loss: 0.0013 - val_mae: 0.0335\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0597 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 0.0014 - val_mae: 0.0339\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mae: 0.0505 - val_loss: 0.0012 - val_mae: 0.0308\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0057 - mae: 0.0551 - val_loss: 0.0011 - val_mae: 0.0297\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0607 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0061 - mae: 0.0606 - val_loss: 0.0021 - val_mae: 0.0410\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - mae: 0.0547 - val_loss: 0.0027 - val_mae: 0.0464\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0051 - mae: 0.0601 - val_loss: 0.0025 - val_mae: 0.0445\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0571 - val_loss: 0.0018 - val_mae: 0.0390\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0060 - mae: 0.0594 - val_loss: 0.0013 - val_mae: 0.0329\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0011 - val_mae: 0.0281\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0515 - val_loss: 0.0010 - val_mae: 0.0257\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - mae: 0.0517 - val_loss: 0.0012 - val_mae: 0.0300\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0015 - val_mae: 0.0347\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0500 - val_loss: 0.0014 - val_mae: 0.0342\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0500 - val_loss: 0.0012 - val_mae: 0.0306\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.0012 - val_mae: 0.0311\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0520 - val_loss: 0.0014 - val_mae: 0.0338\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0437 - val_loss: 0.0014 - val_mae: 0.0335\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - mae: 0.0503 - val_loss: 0.0012 - val_mae: 0.0295\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0475 - val_loss: 0.0010 - val_mae: 0.0260\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0546 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0566 - val_loss: 0.0016 - val_mae: 0.0365\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0046 - mae: 0.0526 - val_loss: 0.0027 - val_mae: 0.0461\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0045 - mae: 0.0557 - val_loss: 0.0025 - val_mae: 0.0445\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0012 - val_mae: 0.0296\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0433 - val_loss: 9.0651e-04 - val_mae: 0.0232\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0561 - val_loss: 8.1215e-04 - val_mae: 0.0217\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0014 - val_mae: 0.0331\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0029 - val_mae: 0.0460\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0021 - val_mae: 0.0404\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0054 - mae: 0.0562 - val_loss: 9.3805e-04 - val_mae: 0.0274\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - mae: 0.0507 - val_loss: 7.7783e-04 - val_mae: 0.0233\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0540 - val_loss: 0.0010 - val_mae: 0.0291\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0016 - val_mae: 0.0371\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0495 - val_loss: 0.0020 - val_mae: 0.0402\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.0011 - val_mae: 0.0293\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0495 - val_loss: 9.0771e-04 - val_mae: 0.0198\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0485 - val_loss: 9.4716e-04 - val_mae: 0.0248\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0500 - val_loss: 0.0016 - val_mae: 0.0367\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0046 - mae: 0.0505 - val_loss: 0.0029 - val_mae: 0.0489\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0583 - val_loss: 0.0026 - val_mae: 0.0459\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0010 - val_mae: 0.0284\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0545 - val_loss: 6.4683e-04 - val_mae: 0.0191\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mae: 0.0473 - val_loss: 5.9860e-04 - val_mae: 0.0179\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0505 - val_loss: 7.2169e-04 - val_mae: 0.0232\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - mae: 0.0444 - val_loss: 0.0011 - val_mae: 0.0297\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0013 - val_mae: 0.0309\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - mae: 0.0508 - val_loss: 6.8185e-04 - val_mae: 0.0221\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0483 - val_loss: 5.7734e-04 - val_mae: 0.0189\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0050 - mae: 0.0507 - val_loss: 7.2810e-04 - val_mae: 0.0227\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0449 - val_loss: 0.0011 - val_mae: 0.0289\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0439 - val_loss: 0.0013 - val_mae: 0.0326\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0443 - val_loss: 8.9389e-04 - val_mae: 0.0269\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - mae: 0.0448 - val_loss: 5.7737e-04 - val_mae: 0.0187\n"
     ]
    }
   ],
   "source": [
    "# Data is already in correct shape for LSTM: (samples, timesteps, features)\n",
    "print(f\"X_train_scaled_ts shape: {X_train_scaled_ts.shape}\")\n",
    "print(f\"X_test_scaled_ts shape: {X_test_scaled_ts.shape}\")\n",
    "\n",
    "# Build Time Series LSTM Model\n",
    "model_ts = Sequential()\n",
    "model_ts.add(LSTM(units=128, return_sequences=True, input_shape=(X_train_scaled_ts.shape[1], X_train_scaled_ts.shape[2])))\n",
    "model_ts.add(Dropout(0.2))\n",
    "model_ts.add(LSTM(units=64, return_sequences=False))\n",
    "model_ts.add(Dropout(0.2))\n",
    "model_ts.add(Dense(32, activation='relu'))\n",
    "model_ts.add(Dense(1))\n",
    "\n",
    "model_ts.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "model_ts.summary()\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "history_ts = model_ts.fit(\n",
    "    X_train_scaled_ts, \n",
    "    y_train_scaled_ts, \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "870fe91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "=== Time Series LSTM Results ===\n",
      "\n",
      "Scaled Data Metrics:\n",
      "Mean Squared Error: 0.004052\n",
      "Mean Absolute Error: 0.043438\n",
      "R² Score: 0.947912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions_ts = model_ts.predict(X_test_scaled_ts)\n",
    "\n",
    "# Calculate metrics on scaled data\n",
    "mse_scaled = mean_squared_error(y_test_scaled_ts, predictions_ts.flatten())\n",
    "mae_scaled = mean_absolute_error(y_test_scaled_ts, predictions_ts.flatten())\n",
    "r2_scaled = r2_score(y_test_scaled_ts, predictions_ts.flatten())\n",
    "\n",
    "\n",
    "print(\"=== Time Series LSTM Results ===\")\n",
    "print(\"\\nScaled Data Metrics:\")\n",
    "print(f\"Mean Squared Error: {mse_scaled:.6f}\")\n",
    "print(f\"Mean Absolute Error: {mae_scaled:.6f}\")\n",
    "print(f\"R² Score: {r2_scaled:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e49aaae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hyperparameter Tuning ===\n",
      "\n",
      "Testing combination 1/5: {'lstm_units': 128, 'dropout': 0.2, 'batch_size': 32, 'lr': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: -0.100172\n",
      "\n",
      "Testing combination 2/5: {'lstm_units': 256, 'dropout': 0.1, 'batch_size': 32, 'lr': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.903468\n",
      "\n",
      "Testing combination 3/5: {'lstm_units': 64, 'dropout': 0.3, 'batch_size': 16, 'lr': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.569518\n",
      "\n",
      "Testing combination 4/5: {'lstm_units': 128, 'dropout': 0.1, 'batch_size': 64, 'lr': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: -0.090683\n",
      "\n",
      "Testing combination 5/5: {'lstm_units': 256, 'dropout': 0.2, 'batch_size': 16, 'lr': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin/Desktop/Internship/code/Indonesia-rice-prediction/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.912559\n",
      "\n",
      "=== Best Hyperparameters Found ===\n",
      "Best parameters: {'lstm_units': 256, 'dropout': 0.2, 'batch_size': 16, 'lr': 0.01}\n",
      "Best R² Score: 0.912559\n",
      "\n",
      "=== Final Tuned Model Results ===\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Best Model - Scaled Data Metrics:\n",
      "Mean Squared Error: 0.006802\n",
      "Mean Absolute Error: 0.046638\n",
      "R² Score: 0.912559\n"
     ]
    }
   ],
   "source": [
    "# 6th cell: Hyperparameter tuning for maximum accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import itertools\n",
    "\n",
    "print(\"=== Hyperparameter Tuning ===\")\n",
    "\n",
    "# Define hyperparameter combinations to try\n",
    "lstm_units_options = [64, 128, 256]\n",
    "dropout_rates = [0.1, 0.2, 0.3]\n",
    "batch_sizes = [16, 32, 64]\n",
    "learning_rates = [0.001, 0.01]\n",
    "\n",
    "best_r2 = -float('inf')\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Grid search through hyperparameters (simplified for computational efficiency)\n",
    "param_combinations = [\n",
    "    {'lstm_units': 128, 'dropout': 0.2, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'lstm_units': 256, 'dropout': 0.1, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'lstm_units': 64, 'dropout': 0.3, 'batch_size': 16, 'lr': 0.01},\n",
    "    {'lstm_units': 128, 'dropout': 0.1, 'batch_size': 64, 'lr': 0.001},\n",
    "    {'lstm_units': 256, 'dropout': 0.2, 'batch_size': 16, 'lr': 0.01}\n",
    "]\n",
    "\n",
    "for i, params in enumerate(param_combinations):\n",
    "    print(f\"\\nTesting combination {i+1}/{len(param_combinations)}: {params}\")\n",
    "    \n",
    "    # Build model with current hyperparameters\n",
    "    model_tuned = Sequential()\n",
    "    model_tuned.add(LSTM(units=params['lstm_units'], return_sequences=True, \n",
    "                        input_shape=(X_train_scaled_ts.shape[1], X_train_scaled_ts.shape[2])))\n",
    "    model_tuned.add(Dropout(params['dropout']))\n",
    "    model_tuned.add(LSTM(units=params['lstm_units']//2, return_sequences=False))\n",
    "    model_tuned.add(Dropout(params['dropout']))\n",
    "    model_tuned.add(Dense(32, activation='relu'))\n",
    "    model_tuned.add(Dense(1))\n",
    "    \n",
    "    # Compile with current learning rate\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=params['lr'])\n",
    "    model_tuned.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    # Train model\n",
    "    history_tuned = model_tuned.fit(\n",
    "        X_train_scaled_ts, \n",
    "        y_train_scaled_ts,\n",
    "        epochs=50,  # Reduced for tuning efficiency\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    predictions_tuned = model_tuned.predict(X_test_scaled_ts, verbose=0)\n",
    "    r2_tuned = r2_score(y_test_scaled_ts, predictions_tuned.flatten())\n",
    "    \n",
    "    print(f\"R² Score: {r2_tuned:.6f}\")\n",
    "    \n",
    "    # Update best model if this one is better\n",
    "    if r2_tuned > best_r2:\n",
    "        best_r2 = r2_tuned\n",
    "        best_params = params.copy()\n",
    "        best_model = model_tuned\n",
    "        \n",
    "print(f\"\\n=== Best Hyperparameters Found ===\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best R² Score: {best_r2:.6f}\")\n",
    "\n",
    "# Final evaluation with best model\n",
    "print(f\"\\n=== Final Tuned Model Results ===\")\n",
    "best_predictions = best_model.predict(X_test_scaled_ts)\n",
    "\n",
    "# Metrics on scaled data\n",
    "best_mse_scaled = mean_squared_error(y_test_scaled_ts, best_predictions.flatten())\n",
    "best_mae_scaled = mean_absolute_error(y_test_scaled_ts, best_predictions.flatten())\n",
    "best_r2_scaled = r2_score(y_test_scaled_ts, best_predictions.flatten())\n",
    "\n",
    "print(\"\\nBest Model - Scaled Data Metrics:\")\n",
    "print(f\"Mean Squared Error: {best_mse_scaled:.6f}\")\n",
    "print(f\"Mean Absolute Error: {best_mae_scaled:.6f}\")\n",
    "print(f\"R² Score: {best_r2_scaled:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
